model_type: grok  # Options: grok, local, openai
model_name: grok-4-fast-reasoning
endpoint: https://api.x.ai/v1 # http://127.0.0.1:1234 # For local LM Studio server or Ollama server
api_key_var: XAI_API_KEY
max_iterations: 3
temperature: 0.7
max_tokens: 2048
search_results_limit: 5